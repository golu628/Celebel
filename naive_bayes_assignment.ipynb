{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFoD6AE8aQDCiNMPzhLWEm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/golu628/Celebel/blob/main/naive_bayes_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUEZ5vG6W9EK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Q1. Probability of Smoker Given Use of Health Plan\n",
        "Given:\n",
        "\n",
        "P(Uses Plan) = 0.70\n",
        "\n",
        "P(Smoker | Uses Plan) = 0.40\n",
        "\n",
        "So, P(Smoker | Uses Plan) = 0.40\n",
        "‚úîÔ∏è That‚Äôs already the conditional probability:\n",
        "\n",
        "Probability that an employee is a smoker given that they use the health insurance plan is 0.40 or 40%.\n",
        "\n",
        "‚úÖ Q2. Bernoulli vs Multinomial Naive Bayes\n",
        "\n",
        "Feature\tBernoulli Naive Bayes\tMultinomial Naive Bayes\n",
        "Input Type\tBinary features (0/1)\tCount-based (integer) features\n",
        "Ideal For\tText classification with binary word occurrence\tText classification with term frequency or count\n",
        "Output\tBased on presence/absence of features\tBased on frequency of features\n",
        "Example\tSpam detection with presence/absence of words\tSpam detection with word counts\n",
        "‚úÖ Q3. How Bernoulli Naive Bayes Handles Missing Values\n",
        "üëâ It doesn‚Äôt handle missing values automatically.\n",
        "\n",
        "You must impute or remove missing values before training.\n",
        "\n",
        "Use SimpleImputer from sklearn.impute if needed.\n",
        "\n",
        "‚úÖ Q4. Can Gaussian Naive Bayes Be Used for Multi-Class?\n",
        "‚úîÔ∏è Yes.\n",
        "\n",
        "GaussianNB in scikit-learn supports multi-class classification.\n",
        "\n",
        "It uses the assumption that features follow a normal distribution per class.\n",
        "\n",
        "‚úÖ Q5. Spambase Naive Bayes Assignment (Implementation Plan)\n",
        "üì¶ Data Preparation\n",
        "Download from: UCI Spambase Dataset\n",
        "\n",
        "Load the dataset (CSV format) into a DataFrame.\n",
        "\n",
        "üîß Model Implementation\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
        "from sklearn.preprocessing import Binarizer, MinMaxScaler\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"spambase.data\", header=None)\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Preprocessing for BernoulliNB (binary)\n",
        "X_binary = Binarizer().fit_transform(X)\n",
        "\n",
        "# Evaluation metrics\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1'\n",
        "}\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Models\n",
        "bnb = BernoulliNB()\n",
        "mnb = MultinomialNB()\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Cross-validation\n",
        "results_bnb = cross_validate(bnb, X_binary, y, cv=cv, scoring=scoring)\n",
        "results_mnb = cross_validate(mnb, X, y, cv=cv, scoring=scoring)\n",
        "results_gnb = cross_validate(gnb, X, y, cv=cv, scoring=scoring)\n",
        "\n",
        "# Helper to display results\n",
        "def show_results(name, results):\n",
        "    print(f\"\\n{name} Performance:\")\n",
        "    for metric in scoring:\n",
        "        print(f\"{metric.capitalize()}: {results[f'test_{metric}'].mean():.4f}\")\n",
        "\n",
        "show_results(\"BernoulliNB\", results_bnb)\n",
        "show_results(\"MultinomialNB\", results_mnb)\n",
        "show_results(\"GaussianNB\", results_gnb)\n",
        "üß† Discussion of Results\n",
        "MultinomialNB usually performs best for text/spam detection because it works well with frequency-based features.\n",
        "\n",
        "BernoulliNB may underperform due to binary simplification of features.\n",
        "\n",
        "GaussianNB assumes normal distribution, which isn‚Äôt ideal for text data (non-continuous).\n",
        "\n",
        "‚úÖ Conclusion\n",
        "Best performer: Likely MultinomialNB, as expected in spam detection.\n",
        "\n",
        "Limitation: Naive Bayes assumes feature independence ‚Äî often not true in real datasets.\n",
        "\n",
        "Future Work:\n",
        "\n",
        "Try TF-IDF preprocessing\n",
        "\n",
        "Apply ensemble methods or hybrid models\n",
        "\n",
        "Address correlated features\n",
        "\n"
      ],
      "metadata": {
        "id": "gwIgjRxAXB_H"
      }
    }
  ]
}